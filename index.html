<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Observability Demo</title>
    <link rel="stylesheet" href="styles.css">
    <!-- Datadog RUM SDK -->
    <script src="https://www.datadoghq-browser-agent.com/datadog-rum-v4.js" crossorigin="anonymous"></script>
    <script src="https://www.datadoghq-browser-agent.com/datadog-logs-v4.js" crossorigin="anonymous"></script>

    <!-- Initialize Datadog RUM with Hardcoded Configuration -->
    <script>
        (function() {
            // Function to get URL parameters
            function getUrlParameter(name) {
                const urlParams = new URLSearchParams(window.location.search);
                return urlParams.get(name);
            }

            // Function to get from localStorage with fallback
            function getConfigValue(key, defaultValue) {
                const urlValue = getUrlParameter(key);
                if (urlValue) {
                    localStorage.setItem(key, urlValue);
                    return urlValue;
                }
                return localStorage.getItem(key) || defaultValue;
            }

            // Flexible Datadog RUM configuration with multiple sources
            const DATADOG_CONFIG = {
                // Can be overridden via URL parameters: ?dd_client_token=xxx&dd_app_id=xxx&dd_site=xxx
                clientToken: getConfigValue('dd_client_token', 'pub941f8b1659ac0af8597b9c41a0cfe121'),
                applicationId: getConfigValue('dd_app_id', 'fde3bfb4-cc7c-49ad-82c2-9fed18ce298c'),
                site: getConfigValue('dd_site', 'datadoghq.com'),
                service: getConfigValue('dd_service', 'llm-observability-demo'),
                env: getConfigValue('dd_env', 'production'),
                version: getConfigValue('dd_version', '1.0.0'),
                sessionSampleRate: parseInt(getConfigValue('dd_session_sample_rate', '100')),
                sessionReplaySampleRate: parseInt(getConfigValue('dd_replay_sample_rate', '20')),
                trackUserInteractions: getConfigValue('dd_track_interactions', 'true') === 'true',
                trackResources: getConfigValue('dd_track_resources', 'true') === 'true',
                trackLongTasks: getConfigValue('dd_track_long_tasks', 'true') === 'true',
                defaultPrivacyLevel: getConfigValue('dd_privacy_level', 'mask-user-input')
            };

            // Function to initialize Datadog
            function initializeDatadog() {
                // Check if we have valid tokens (these are real working values)
                const hasValidTokens = DATADOG_CONFIG.clientToken &&
                                     DATADOG_CONFIG.applicationId &&
                                     DATADOG_CONFIG.clientToken.startsWith('pub_') &&
                                     DATADOG_CONFIG.applicationId.length > 0;

                if (!hasValidTokens) {
                    console.warn('‚ö†Ô∏è Datadog tokens not configured - RUM not initialized');
                    console.log('üìù To enable Datadog RUM:');
                    console.log('   1. Get your Client Token from Datadog ‚Üí Organization Settings ‚Üí API Keys');
                    console.log('   2. Get your Application ID from Datadog ‚Üí RUM ‚Üí Applications');
                    console.log('   3. Replace the hardcoded values in index.html');
                    
                    // Create placeholder objects to prevent errors
                    window.DD_RUM = window.DD_RUM || {
                        init: () => {},
                        addAction: () => {},
                        addError: () => {},
                        addTiming: () => {},
                        setGlobalContextProperty: () => {},
                        startSessionReplayRecording: () => {}
                    };
                    window.DD_LOGS = window.DD_LOGS || {
                        init: () => {},
                        logger: {
                            info: () => {},
                            error: () => {},
                            warn: () => {}
                        }
                    };
                    return;
                }

                try {
                    // Initialize RUM
                    if (window.DD_RUM) {
                        window.DD_RUM.init(DATADOG_CONFIG);

                        window.DD_RUM.startSessionReplayRecording();

                        // Set global context
                        window.DD_RUM.setGlobalContextProperty('application_type', 'llm_demo');
                        window.DD_RUM.setGlobalContextProperty('deployment_method', 'static_hosting');
                        window.DD_RUM.setGlobalContextProperty('framework', 'vanilla_js');
                        window.DD_RUM.setGlobalContextProperty('demo_version', '1.0.0');
                    }

                    // Initialize Logs
                    if (window.DD_LOGS) {
                        window.DD_LOGS.init({
                            clientToken: DATADOG_CONFIG.clientToken,
                            site: DATADOG_CONFIG.site,
                            service: DATADOG_CONFIG.service,
                            env: DATADOG_CONFIG.env,
                            version: DATADOG_CONFIG.version,
                            sessionSampleRate: DATADOG_CONFIG.sessionSampleRate,
                            silentMultipleInit: true
                        });
                    }

                        console.log('‚úÖ Datadog RUM and Logs initialized successfully');
                        console.log('üìä RUM Configuration:', {
                            site: DATADOG_CONFIG.site,
                            service: DATADOG_CONFIG.service,
                            env: DATADOG_CONFIG.env,
                            version: DATADOG_CONFIG.version,
                            clientToken: DATADOG_CONFIG.clientToken.substring(0, 10) + '...',
                            applicationId: DATADOG_CONFIG.applicationId.substring(0, 8) + '...'
                        });

                        // Show configuration source
                        const hasUrlParams = window.location.search.includes('dd_');
                        const hasLocalStorage = Object.keys(DATADOG_CONFIG).some(key => 
                            localStorage.getItem('dd_' + key.replace(/([A-Z])/g, '_$1').toLowerCase())
                        );
                        
                        if (hasUrlParams) {
                            console.log('üîß Configuration loaded from URL parameters');
                        } else if (hasLocalStorage) {
                            console.log('üíæ Configuration loaded from localStorage');
                        } else {
                            console.log('üè† Using default hardcoded configuration');
                        }

                    // Track page load
                    if (window.DD_RUM) {
                        window.DD_RUM.addAction('page_loaded', {
                            page_type: 'llm_demo',
                            timestamp: new Date().toISOString(),
                            url: window.location.href,
                            user_agent: navigator.userAgent
                        });
                    }

                } catch (error) {
                    console.error('‚ùå Failed to initialize Datadog:', error);
                }
            }

            // Start initialization when DOM is ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', initializeDatadog);
            } else {
                initializeDatadog();
            }

            // Global functions for configuration management
            window.refreshConfiguration = function() {
                const configDisplay = document.getElementById('current-config');
                if (configDisplay) {
                    configDisplay.innerHTML = `
                        <div class="config-item">
                            <strong>Client Token:</strong> ${DATADOG_CONFIG.clientToken.substring(0, 10)}...
                        </div>
                        <div class="config-item">
                            <strong>Application ID:</strong> ${DATADOG_CONFIG.applicationId.substring(0, 8)}...
                        </div>
                        <div class="config-item">
                            <strong>Site:</strong> ${DATADOG_CONFIG.site}
                        </div>
                        <div class="config-item">
                            <strong>Service:</strong> ${DATADOG_CONFIG.service}
                        </div>
                        <div class="config-item">
                            <strong>Environment:</strong> ${DATADOG_CONFIG.env}
                        </div>
                        <div class="config-item">
                            <strong>Version:</strong> ${DATADOG_CONFIG.version}
                        </div>
                        <div class="config-item">
                            <strong>Session Sample Rate:</strong> ${DATADOG_CONFIG.sessionSampleRate}%
                        </div>
                        <div class="config-item">
                            <strong>Replay Sample Rate:</strong> ${DATADOG_CONFIG.sessionReplaySampleRate}%
                        </div>
                    `;
                }
            };

            window.clearLocalStorage = function() {
                const keys = Object.keys(localStorage).filter(key => key.startsWith('dd_'));
                keys.forEach(key => localStorage.removeItem(key));
                alert('LocalStorage cleared! Refresh the page to use default configuration.');
            };

            window.testDatadogConnection = function() {
                if (window.DD_RUM) {
                    window.DD_RUM.addAction('test_connection', {
                        test_type: 'manual_test',
                        timestamp: new Date().toISOString()
                    });
                    alert('Test action sent to Datadog! Check your RUM dashboard.');
                } else {
                    alert('Datadog RUM not initialized. Check console for errors.');
                }
            };

            // Auto-refresh configuration display when page loads
            setTimeout(() => {
                if (window.refreshConfiguration) {
                    window.refreshConfiguration();
                }
            }, 1000);
        })();
    </script>
</head>
<body>
    <div class="container">
        <header>
            <h1>ü§ñ LLM Observability Demo</h1>
            <p>Comprehensive monitoring of AI-powered applications with Datadog</p>
        </header>

        <div class="mode-selector">
            <button class="mode-btn active" data-mode="chat">üí¨ Chat</button>
            <button class="mode-btn" data-mode="summarize">üìù Summarize</button>
            <button class="mode-btn" data-mode="codegen">üíª Code Gen</button>
        </div>

        <div class="main-content">
            <div class="chat-container" id="chatMode">
                <div class="chat-messages" id="chatMessages"></div>
                <div class="input-container">
                    <input type="text" id="chatInput" placeholder="Ask me anything..." />
                    <button id="sendBtn">Send</button>
                </div>
            </div>

            <div class="summarize-container hidden" id="summarizeMode">
                <div class="input-section">
                    <h3>Text Summarization</h3>
                    <textarea id="summarizeInput" placeholder="Paste your text here to summarize..."></textarea>
                    <button id="summarizeBtn">Summarize</button>
                </div>
                <div class="output-section">
                    <h3>Summary</h3>
                    <div id="summarizeOutput"></div>
                </div>
            </div>

            <div class="codegen-container hidden" id="codegenMode">
                <div class="input-section">
                    <h3>Code Generation</h3>
                    <textarea id="codegenInput" placeholder="Describe what code you want me to generate..."></textarea>
                    <button id="codegenBtn">Generate Code</button>
                </div>
                <div class="output-section">
                    <h3>Generated Code</h3>
                    <pre id="codegenOutput"></pre>
                </div>
            </div>
        </div>

        <div class="metrics-panel">
            <h3>üìä Session Metrics</h3>
            <div class="metrics-grid">
                <div class="metric">
                    <span class="metric-label">Tokens Used:</span>
                    <span class="metric-value" id="tokenCount">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Estimated Cost:</span>
                    <span class="metric-value" id="costEstimate">$0.00</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Requests:</span>
                    <span class="metric-value" id="requestCount">0</span>
                </div>
                <div class="metric">
                    <span class="metric-label">Avg Response Time:</span>
                    <span class="metric-value" id="avgResponseTime">0ms</span>
                </div>
            </div>
        </div>

        <div class="knowledge-base-panel">
            <h3>üìö LLM Observability Knowledge Base</h3>
            <div class="knowledge-sections">
                
                <div class="knowledge-section">
                    <h4>üéØ The Application Blueprint: Customer Support AI Assistant</h4>
                    <div class="knowledge-content">
                        <p><strong>Core Functionality</strong>: The "Furnish Hub" AI assistant handles customer inquiries including:</p>
                        <ul>
                            <li>Product information and recommendations</li>
                            <li>Pricing and availability queries</li>
                            <li>Store policies (returns, shipping, etc.)</li>
                            <li>General furniture questions</li>
                        </ul>
                        
                        <p><strong>Technical Stack</strong>:</p>
                        <ul>
                            <li><strong>Language</strong>: Python for AI/ML development</li>
                            <li><strong>LLM Provider</strong>: OpenAI (GPT-4o-mini, GPT-4o)</li>
                            <li><strong>Observability Platform</strong>: Datadog LLM Observability</li>
                        </ul>
                        
                        <p><strong>Key Observability Challenges Demonstrated</strong>:</p>
                        <ol>
                            <li><strong>Performance & Cost Management</strong>: Token consumption tracking and API latency monitoring</li>
                            <li><strong>Debugging & Quality Analysis</strong>: Full prompt/response capture for debugging</li>
                            <li><strong>Semantic Failures & Hallucinations</strong>: Detection of "soft failures" where API succeeds but content is incorrect</li>
                            <li><strong>Data Privacy & Security</strong>: PII detection and redaction capabilities</li>
                        </ol>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üîç The New Imperative of AI Application Monitoring</h4>
                    <div class="knowledge-content">
                        <h5>Beyond Deterministic Systems: Unique LLM Challenges</h5>
                        
                        <p><strong>The Non-Deterministic Nature</strong>: Unlike traditional software, LLMs are inherently probabilistic. The same prompt can generate different responses, requiring statistical performance baselines rather than exact-match testing.</p>
                        
                        <p><strong>The "Black Box" Problem</strong>: Multi-billion parameter LLMs have opaque internal reasoning, making semantic failures (hallucinations, bias propagation, off-topic responses) more critical than technical exceptions.</p>
                        
                        <p><strong>Vast Input Space</strong>: Natural language inputs create an effectively infinite, unstructured space that opens doors to unique vulnerabilities like prompt injection attacks.</p>
                        
                        <h5>The Three Pillars of LLM Observability</h5>
                        
                        <div class="pillar">
                            <h6>1. Execution Tracing (The "How")</h6>
                            <ul>
                                <li><strong>Traces & Spans</strong>: End-to-end request journey visualization</li>
                                <li><strong>Generations</strong>: Specialized spans for LLM calls with metadata</li>
                                <li><strong>Retrievals & Tool Calls</strong>: Extended tracing for RAG and agentic systems</li>
                            </ul>
                        </div>
                        
                        <div class="pillar">
                            <h6>2. Qualitative Evaluation (The "What")</h6>
                            <ul>
                                <li><strong>Key Metrics</strong>: Accuracy, relevance, consistency, faithfulness, safety</li>
                                <li><strong>Evaluation Methods</strong>: Structural validation, LLM-as-judge, human feedback</li>
                                <li><strong>Quality Assurance</strong>: Systematic monitoring of semantic performance</li>
                            </ul>
                        </div>
                        
                        <div class="pillar">
                            <h6>3. Quantitative Monitoring (The "How Much")</h6>
                            <ul>
                                <li><strong>Performance Metrics</strong>: Latency, throughput, error rates</li>
                                <li><strong>Cost Metrics</strong>: Granular token usage tracking (prompt, completion, total)</li>
                                <li><strong>Business Metrics</strong>: User experience, satisfaction, task completion</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üè¢ Organizational Impact: Breaking Down Silos</h4>
                    <div class="knowledge-content">
                        <p>LLM observability forces convergence between Data Science, DevOps, and Security teams:</p>
                        <ul>
                            <li><strong>Data Scientists</strong>: Focus on prompt engineering and model accuracy</li>
                            <li><strong>DevOps Engineers</strong>: Concerned with reliability, latency, and infrastructure costs</li>
                            <li><strong>Security Engineers</strong>: Protecting against data leakage and novel attack vectors</li>
                        </ul>
                        <p>An observability platform becomes the common ground, providing shared language and unified data views that enable collaborative, cross-functional AI application management.</p>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üíº Business Case for LLM Observability</h4>
                    <div class="knowledge-content">
                        <div class="business-benefit">
                            <h6>Proactive Performance Optimization</h6>
                            <p>Shift from reactive troubleshooting to proactive optimization through performance baselines and deviation monitoring.</p>
                        </div>
                        
                        <div class="business-benefit">
                            <h6>Strategic Cost Management</h6>
                            <p>Granular insights for identifying inefficient prompt patterns and balancing model complexity with performance requirements.</p>
                        </div>
                        
                        <div class="business-benefit">
                            <h6>Enhanced User Experience</h6>
                            <p>Connecting technical metrics to user outcomes (feedback scores, task completion rates) to focus optimization efforts.</p>
                        </div>
                        
                        <div class="business-benefit">
                            <h6>Robust Risk Mitigation</h6>
                            <p>Comprehensive audit trails, systematic detection of harmful outputs, and protection against security risks like prompt injection.</p>
                        </div>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üõ†Ô∏è Datadog LLM Observability: Unified Platform</h4>
                    <div class="knowledge-content">
                        <h5>Core Platform Features</h5>
                        
                        <div class="feature">
                            <h6>End-to-End Tracing</h6>
                            <p>Complete LLM chain visualization with detailed metadata, input-output data, errors, latency, and token usage.</p>
                        </div>
                        
                        <div class="feature">
                            <h6>Out-of-the-Box Dashboards</h6>
                            <p>Pre-built dashboards for immediate operational metrics across all major LLM providers (OpenAI, Anthropic, Amazon Bedrock, Google Vertex AI).</p>
                        </div>
                        
                        <div class="feature">
                            <h6>Quality & Safety Evaluations</h6>
                            <p>Automatic quality checks (failure to answer, off-topic responses, negative sentiment) plus custom evaluation capabilities.</p>
                        </div>
                        
                        <div class="feature">
                            <h6>Security & Privacy Scanning</h6>
                            <p>Built-in PII detection and redaction using Datadog Sensitive Data Scanner, plus prompt injection detection.</p>
                        </div>
                        
                        <div class="feature">
                            <h6>Prompt & Response Clustering</h6>
                            <p>Semantic clustering to identify systemic issues and performance drifts by grouping similar low-quality interactions.</p>
                        </div>
                        
                        <h5>Holistic Observability Ecosystem</h5>
                        
                        <div class="ecosystem-benefit">
                            <h6>Seamless APM Correlation</h6>
                            <p>LLM traces integrated with traditional APM traces, enabling complete request flow visibility from browser clicks through backend services to LLM calls.</p>
                        </div>
                        
                        <div class="ecosystem-benefit">
                            <h6>Unified Logs, Metrics, and Traces</h6>
                            <p>Full integration of observability's three pillars, allowing immediate correlation between LLM traces, application logs, and infrastructure metrics.</p>
                        </div>
                        
                        <div class="ecosystem-benefit">
                            <h6>Strategic Advantage</h6>
                            <p>Unlike standalone LLM tools that create observability silos, Datadog treats LLMs as first-class citizens within the broader application architecture.</p>
                        </div>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üîß Implementation Blueprint</h4>
                    <div class="knowledge-content">
                        <h5>Environment Configuration</h5>
                        
                        <p><strong>API Keys Required</strong>:</p>
                        <ul>
                            <li>OpenAI API Key: For LLM interactions</li>
                            <li>Datadog API Key: For observability data transmission</li>
                        </ul>
                        
                        <h5>Automatic Instrumentation with ddtrace-run</h5>
                        
                        <p><strong>The Magic Command</strong>:</p>
                        <pre><code>export OPENAI_API_KEY="&lt;YOUR_OPENAI_API_KEY&gt;"
DD_LLMOBS_ENABLED=1 \
DD_API_KEY="&lt;YOUR_DATADOG_API_KEY&gt;" \
DD_LLMOBS_ML_APP="furnish-hub-support-ai" \
DD_SITE="datadoghq.com" \
DD_LLMOBS_AGENTLESS_ENABLED=1 \
ddtrace-run python main.py</code></pre>
                        
                        <h5>Advanced Techniques for Production</h5>
                        
                        <div class="technique">
                            <h6>Custom Tags for Business Context</h6>
                            <pre><code>from ddtrace import tracer
span = tracer.current_span()
if span:
    span.set_tag("customer.id", user_id)
    span.set_tag("session.id", session_id)
    span.set_tag("user.subscription_tier", "premium")</code></pre>
                        </div>
                        
                        <div class="technique">
                            <h6>Proactive Monitoring Strategy</h6>
                            <ul>
                                <li><strong>Cost Anomaly Detection</strong>: Monitor token usage spikes</li>
                                <li><strong>Latency Spike Alerts</strong>: Track API performance against SLOs</li>
                                <li><strong>Error Rate Monitoring</strong>: Detect API issues and configuration problems</li>
                                <li><strong>PII Leakage Notifications</strong>: Security alerts for sensitive data detection</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="knowledge-section">
                    <h4>üéØ Conclusion: Towards Reliable AI Operations</h4>
                    <div class="knowledge-content">
                        <p>The journey from experimental AI to enterprise-grade AI requires operational excellence. LLM observability transforms the opaque "black box" of neural networks into a transparent, manageable "glass box" that enables:</p>
                        
                        <ul>
                            <li><strong>Reliable Performance</strong>: Proactive monitoring and optimization</li>
                            <li><strong>Cost Control</strong>: Strategic management of token usage and model selection</li>
                            <li><strong>Quality Assurance</strong>: Systematic evaluation and improvement processes</li>
                            <li><strong>Security Compliance</strong>: Protection against novel AI-specific risks</li>
                            <li><strong>Cross-functional Collaboration</strong>: Unified platform for diverse team needs</li>
                        </ul>
                        
                        <p><strong>For organizations deploying AI at scale, comprehensive LLM observability is not just a best practice‚Äîit's the foundation upon which the future of AI operations will be built.</strong></p>
                    </div>
                </div>

            </div>
        </div>

        <div class="config-panel">
            <h3>‚öôÔ∏è Configuration</h3>
            
            <div class="config-section">
                <h4>ü§ñ OpenAI Configuration</h4>
                <div class="config-item">
                    <label for="apiKey">OpenAI API Key:</label>
                    <input type="password" id="apiKey" placeholder="sk-..." />
                </div>
                <div class="config-item">
                    <label for="model">Model:</label>
                    <select id="model">
                        <option value="gpt-4o-mini">GPT-4o Mini</option>
                        <option value="gpt-4o">GPT-4o</option>
                        <option value="gpt-3.5-turbo">GPT-3.5 Turbo</option>
                    </select>
                </div>
            </div>

            <div class="config-section">
                <h4>üìä Datadog RUM Configuration</h4>
                <div class="config-info">
                    <p><strong>Current Configuration:</strong></p>
                    <div id="current-config" class="config-display">
                        <p>Loading configuration...</p>
                    </div>
                </div>
                
                <div class="config-methods">
                    <h5>Configuration Methods:</h5>
                    <div class="method">
                        <h6>1. URL Parameters (Recommended for Testing)</h6>
                        <p>Add parameters to the URL to override configuration:</p>
                        <code>?dd_client_token=pub_xxx&dd_app_id=xxx&dd_site=datadoghq.com</code>
                        <div class="url-examples">
                            <p><strong>Examples:</strong></p>
                            <ul>
                                <li><code>?dd_client_token=pub_xxx&dd_app_id=xxx</code> - Override tokens</li>
                                <li><code>?dd_site=datadoghq.eu</code> - Use EU site</li>
                                <li><code>?dd_env=staging&dd_version=2.0.0</code> - Set environment</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="method">
                        <h6>2. Browser localStorage</h6>
                        <p>Values are automatically saved to localStorage when using URL parameters.</p>
                        <button onclick="clearLocalStorage()">Clear Saved Configuration</button>
                    </div>
                    
                    <div class="method">
                        <h6>3. Default Hardcoded Values</h6>
                        <p>Uses safe, publicly exposed demo values if no overrides are provided.</p>
                    </div>
                </div>
                
                <div class="button-group">
                    <button onclick="refreshConfiguration()">Refresh Config Display</button>
                    <button onclick="testDatadogConnection()">Test Datadog Connection</button>
                </div>
            </div>

        </div>
    </div>

    <!-- Load our application scripts -->
    <script src="js/datadog.js"></script>
    <script src="js/openai.js"></script>
    <script src="js/ui.js"></script>
    <script src="js/app.js"></script>
</body>
</html>
